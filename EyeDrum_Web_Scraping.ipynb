{"cells":[{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":996865,"status":"ok","timestamp":1633014499284,"user":{"displayName":"Rachel Calder","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gh2Wz6H4Rn3V2JBY9lEB8zJIl8UF2eb9uif5Ee2lg=s64","userId":"07966584384508306396"},"user_tz":240},"id":"YDuIyS5Q9t0L","outputId":"acf0b1c1-4c0f-44b0-d418-f3cb8be780e1"},"outputs":[],"source":["#!/usr/bin/env python3\n","# -*- coding: utf-8 -*-\n","\"\"\"\n","Created on Fri Sep  4 13:20:25 2020\n","This script obtains web content.\n","\n","@author: rachelcalder\n","@author: Jason Kim (edits for scraping DOM nodes)\n","colors = [\"FF6666\", \"9999FF\", \"FF9933\", \"9966CC\", \"66CC66\"]\n","DONE ART = FF6666\n","FILM = 9999FF \n","SPECIAL = FF9933\n","LITERATURE = 9966CC\n","MUSIC = 66CC66\n","\"\"\"\n","import requests\n","from bs4 import BeautifulSoup \n","import pandas as pd \n","\n","# Rachel - change years to your preference\n","final_table = pd.DataFrame(columns=[\"Name\", \"Date\", \"Time\", \"Price\",\"Description\", \"Links\"]) \n","#print(final_table)\n","for etype in range(1, 6):\n","  for year in range(2004,2022):\n","    for month in range(1, 13):\n","      url = f\"http://www.pd.org/~eyedrum/calendar/index.php?eventTypeId={etype}&month={month}&year={year}\"\n","      #obtain website content\n","      response = requests.get(url)\n","      content = response.content\n","      #restructure url data for readability\n","      soup = BeautifulSoup(content, \"lxml\")\n","      # All events for this (year, month) are in a table with name=layoutOne, left column of the site\n","      leftColumn = soup.find(\"table\", attrs={\"name\": \"layoutOne\"}).find(\"td\")\n","      # Not having ID-ed nodes makes this hard, but all the events have the same CSS attribs\n","      events = leftColumn.find_all(\"table\", attrs={\"width\": \"300\", \"cellspacing\": \"0\", \"cellpadding\": \"0\", \"border\": \"0\"})\n","\n","      # We want the header w/ title, date, time, price, etc. Grab it with CSS background-color\n","      for event in events:\n","        spans = event.find_all(\"span\")\n","        e_name = spans[0].text\n","        if (len(spans) > 2):\n","          e_descr = spans[2].text\n","          #test_link = spans[2].find_all(href=True)\n","          test_link = []\n","          for link in spans[2].findAll('a'):\n","            test_link.append(link.get('href'))\n","        else:\n","          e_descr = \"blank\"\n","          test_link = \"blank\"\n","        # spans[1] containing date/time/price is trickier - convert <br> to \\n to make splitting easier\n","        for br in spans[1].find_all(\"br\"):\n","          br.replace_with(\"\\n\")\n","        # Last line is an empty string; remove. Replace non-breaking space w/ breaking space, too\n","        infoList = spans[1].text.strip().replace(\"\\xa0\", \" \").split(\"\\n\")\n","        e_date = infoList[0]\n","        if (len(infoList) > 1):\n","          e_time = infoList[1]\n","        else:\n","          e_time = \"blank\"\n","        if (len(infoList) > 2):\n","          e_price = infoList[2]\n","        else:\n","          e_price = \"blank\"\n","        to_append = [e_name, e_date, e_time, e_price, e_descr, test_link]\n","        a_series = pd.Series(to_append, index = final_table.columns)\n","        final_table = final_table.append(a_series, ignore_index=True)\n","\n","  print(final_table)\n","########### REPLACE NAME OF THE FILE ##########\n","  final_table.to_csv(\"all_events_type\"+str(etype)+\"_0930.csv\", escapechar=\"\\r\")\n","###########################################################\n","\n","\n","\n"]}],"metadata":{"colab":{"collapsed_sections":[],"name":"J2_Web_Scraping.ipynb","provenance":[{"file_id":"18EhsT1swrtrcpWAzLuoE67wkgFnyh4iB","timestamp":1632502796550},{"file_id":"1jVM-3ZDj191Sx-vQ4O1RNcKYUu1cj3mM","timestamp":1632325183188}]},"kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"name":"python"}},"nbformat":4,"nbformat_minor":0}
